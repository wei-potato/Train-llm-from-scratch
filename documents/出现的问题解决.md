## 问题日志1
Creating optimizer and scheduler
Initializing trainer state
Computing absolute values for logging, eval, and save steps
Logging steps: 5, Eval steps: 5000000, Save steps: 10
Checking accelerator preparation
Preparing model with accelerator
[2024-06-29 14:36:22,014] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-06-29 14:36:45,794] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 27376
[2024-06-29 14:36:45,798] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 27377
[2024-06-29 14:36:45,798] [ERROR] [launch.py:322:sigkill_handler] ['/opt/conda/bin/python3.8', '-u', 'pretrain_clm.py', '--local_rank=1', '--config_name', 'my_tokenizer/config.json', '--tokenizer_name', 'my_tokenizer', '--train_files', '/home/jovyan/data/firefly-pretrain-dataset/output.txt', '--validation_files', '/home/jovyan/data/firefly-pretrain-dataset/output.txt', '--per_device_train_batch_size', '20', '--per_device_eval_batch_size', '20', '--do_train', '--output_dir', 'output_model', '--evaluation_strategy', 'steps', '--use_fast_tokenizer', 'false', '--max_eval_samples', '500', '--learning_rate', '1e-4', '--gradient_accumulation_steps', '20', '--num_train_epochs', '3', '--warmup_steps', '5000', '--logging_dir', 'output_model/logs', '--logging_strategy', 'steps', '--logging_steps', '5', '--save_strategy', 'steps', '--preprocessing_num_workers', '10', '--save_steps', '10', '--eval_steps', '5000000', '--save_total_limit', '2000', '--seed', '42', '--disable_tqdm', 'false', '--ddp_find_unused_parameters', 'false', '--block_size', '1024', '--overwrite_output_dir', '--report_to', 'tensorboard', '--run_name', 'output_model', '--bf16', '--bf16_full_eval', '--gradient_checkpointing', '--deepspeed', './ds_config_zero2.json', '--ignore_data_skip', 'true', '--ddp_timeout', '18000000'] exits with return code = -7
### 问题原因
Preparing model with accelerator 之后报错
在deepengine 初始化出错，可能是模型配置参数问题
### 问题解决
直接用llama 7b的参数开始训练
## 问题日志2
解压失败
### 原因
训练文件太大，超出zip限制
### 解决办法
分小了传


## cuda驱动安装问题
### 问题原因
多卡服务器节点需要cuda的nvlink，nvlink有一个fabric-manager管理组件  
### 问题解决
按以下步骤安装和驱动版本相同的fabricmanager
wget https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/nvidia-fabricmanager-535_535.161.08-1_amd64.deb
dpkg -i  nvidia-fabricmanager-535_535.161.08-1_amd64.deb
systemctl start nvidia-fabricmanager
systemctl enable nvidia-fabricmanager

